## ðŸ§  PHASE 2: Intermediate NLP â€“ Machine Learning & Vectors

### ðŸ“˜ Concepts to Master:

| Area                           | Subtopics                                   |
| ------------------------------ | ------------------------------------------- |
| **Sequence Models**            | RNN, LSTM, GRU                              |
| **Text Classification (Deep)** | CNN for text, LSTM for sentiment            |
| **Sequence Labeling**          | NER, POS using Bi-LSTM + CRF                |
| **Text Generation**            | Character-level RNNs, Word-level generation |
| **Attention Mechanisms**       | Soft vs hard attention                      |

### ðŸ’» Code Focus:

- Train a Word2Vec model with `gensim`
- Visualize embeddings with `t-SNE`
- Build LSTM for sentiment classification (`IMDB dataset`)
- Implement sequence labeling (Bi-LSTM + CRF) for NER
- Train a character level text generator

### ðŸ“˜ Resources:

- CS224n (Stanford NLP YouTube Series)
- Jay Alammarâ€™s blog ([https://jalammar.github.io/](https://jalammar.github.io/))
- DeepLearning.ai NLP Specialization (Coursera)

### âœ… Project Milestone:

- Build a **chatbot using RNN + attention**
- Build a **text generation model** that mimics Shakespeare or your chat history
