# ðŸ§¹ Text Preprocessing in NLP

Welcome to the **Text Preprocessing** module â€” the foundational step in every NLP pipeline. This module walks through essential concepts and tools required to clean, tokenize, and normalize raw text for effective NLP modeling.

---

## ðŸ“š Topics Covered

1.1) Introduction to NLP

1.2) Text Processing in NLP

1.3) Tokenization in NLP

	1.3.1) Sentence Tokenization
 
	1.3.2) Word Tokenization
 
	1.3.3) Subword Tokenization
 
		1.3.3.A) WordPiece
  
		1.3.3.B) Byte Pair Encoding (BPE)
  
		1.3.3.C) Unigram (SentencePiece)
  
	1.3.4) Character Tokenization
 
1.4) Stemming in NLP

	 1.4.1) Porter Stemmer
  
	 1.4.2) Lancaster Stemmer
  
	 1.4.3) Snowball Stemmer
  
1.5) Lemmatization in NLP

	 1.5.1) WordNet Lemmatizer (NLTK)
  
	 1.5.2) spaCy Lemmatizer
  
	 1.5.3) Stanza (StanfordNLP) Neural-Based Lemmatizer
  
1.6) Stop Words Removal in NLP

	 1.6.1) NLTK Stopword Removal
  
	 1.6.2) spaCy Stopword Removal
  
	 1.6.3) scikit-learn Stopword Removal
  
1.7) Regular Expressions (RegEx)

1.8) Text Normalization


---

## ðŸ§  Learning Outcome

By the end of this module, you will be able to:
- Prepare raw text for downstream NLP tasks
- Choose appropriate preprocessing strategies
- Implement tokenization, stemming, lemmatization, and normalization using multiple libraries

---
