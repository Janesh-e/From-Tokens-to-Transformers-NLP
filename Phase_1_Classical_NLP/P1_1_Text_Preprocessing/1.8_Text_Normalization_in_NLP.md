
# 🧼 TEXT NORMALIZATION in NLP :

### 🔍 What is Text Normalization?

> **Text Normalization** is the process of converting raw text into a standard, consistent, and simplified format so that models can understand and process it effectively.

Different people might write the same thing in multiple ways:
- `U.S.A.` → `USA`
- `HELLO!!` → `hello`
- `10,000` → `10000`
- `l8r`, `later`, `L8r` → `later`

👉 These variations must be **normalized** to treat semantically similar forms the same way.

### 🧱 Why Normalize Text?

|Benefit|Explanation|
|---|---|
|Reduce Noise|Eliminate inconsistencies like capitalization, punctuation, extra spaces|
|Reduce Vocabulary Size|"Cat", "cat", and "CAT" → all become "cat"|
|Improve Token Matching|“1000” vs “1,000” becomes consistent|
|Enhance ML/NLP Model Accuracy|Cleaner input → better understanding by models|

### 🧭 Typical Text Normalization Steps

Here’s the **text normalization flow**:

```plaintext
Raw Text 
  ↓
Lowercasing
  ↓
Removing Punctuation/Special Characters
  ↓
Removing Numbers (optional)
  ↓
Stripping Whitespace
  ↓
Converting Accents
  ↓
Spelling Correction (optional)
  ↓
Contractions Handling
  ↓
Unicode Normalization
  ↓
Lemmatization/Stemming (Already covered)
```

### 🔧 Techniques and Code Examples (Python)

Let’s go through each one in detail.

#### ✅ 1. **Lowercasing**

```python
text = "I Love NLP!"
print(text.lower())  # "i love nlp!"
```

**Why?** Helps treat `Cat` and `cat` as the same word.

#### ✅ 2. **Removing Punctuation**

```python
import string
text = "Hello!!! I love NLP, do you?"
text = text.translate(str.maketrans('', '', string.punctuation))
print(text)  # "Hello I love NLP do you"
```

Or using `re`:

```python
import re
re.sub(r'[^\w\s]', '', text)
```

#### ✅ 3. **Removing Numbers (optional)**

```python
text = "He is 24 years old and earns 5000."
cleaned = re.sub(r'\d+', '', text)
print(cleaned)  # "He is  years old and earns ."
```

Use **carefully** — numbers may be **important** in some tasks (e.g., price classification).

#### ✅ 4. **Stripping Extra Whitespace**

```python
text = "I     love    NLP   "
text = " ".join(text.split())
print(text)  # "I love NLP"
```

#### ✅ 5. **Unicode Normalization**

Useful when working with accented characters (é, ñ, ü etc.)

```python
import unicodedata

text = "café"
text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')
print(text)  # "cafe"
```

#### ✅ 6. **Handling Contractions**

```python
import contractions

text = "I won't go because it's too late."
expanded = contractions.fix(text)
print(expanded)  # "I will not go because it is too late."
```

Expanding contractions is essential for better token and lemma matching.

#### ✅ 7. **Spelling Correction (Optional)**

```python
from textblob import TextBlob

text = "I havv goood speling"
corrected = str(TextBlob(text).correct())
print(corrected)  # "I have good spelling"
```

Or you can use `SymSpell`, `jamspell`, or `hunspell` for large-scale applications.

#### ✅ 8. **Removing Stop Words**

(Already covered in detail earlier)

### 📦 End-to-End Normalization Example

```python
import re, string, unicodedata
import contractions
from textblob import TextBlob

def normalize_text(text):
    text = text.lower()                                           # Lowercase
    text = contractions.fix(text)                                 # Expand contractions
    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')  # Remove accents
    text = re.sub(r'\d+', '', text)                               # Remove numbers
    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation
    text = " ".join(text.split())                                 # Remove extra whitespace
    text = str(TextBlob(text).correct())                          # Correct spelling
    return text

raw = "Héllo! I won't go to the café today because I havv speling issues."
print(normalize_text(raw))
```

**Output:**

```
hello i will not go to the cafe today because i have spelling issues
```

### 🧠 Things to Consider

|Step|When to Use|
|---|---|
|Remove punctuation|Most classification/NLP tasks|
|Keep punctuation|Sentiment/Dialogue/NER tasks|
|Remove numbers|If numbers don't carry meaning|
|Keep numbers|In financial, scientific, product-related contexts|
|Spelling correction|Optional (expensive for large corpora, better in small datasets)|

### 🧪 NLP Libraries Offering Normalization Tools

|Library|What It Offers|
|---|---|
|NLTK|Basic string ops, stopwords, stemming|
|spaCy|Tokenization, lemmatization, stopwords|
|TextBlob|Spelling correction, POS tagging|
|gensim|Preprocessing utilities|
|clean-text|Simple utility for text cleaning|

### ✅ Summary

Text Normalization brings **chaotic raw text** into a **standard, clean, and machine-understandable** form, making it one of the most **crucial preprocessing steps in NLP**.

Would you now like to:

1. Build a **custom normalization pipeline** using spaCy?
2. Continue with the next NLP concept – **POS tagging**?
3. Try a **hands-on exercise** to clean noisy text data?

### 📌 **Text Preprocessing vs Text Normalization**

##### ✅ **Text Preprocessing** – The Broad Category

> **Text Preprocessing** is the **overall process** of transforming raw text into a clean and structured format so it can be used effectively in NLP models.

Think of it like preparing ingredients before cooking: washing, chopping, marinating, etc.

##### 🔹 **Text Normalization** – A Subset of Text Preprocessing

> **Text Normalization** is a **sub-process within text preprocessing** that specifically focuses on **reducing textual variability** and **standardizing** the format of words/phrases.

### ⚙️ Components Breakdown

##### 🧱 **Text Preprocessing Includes**:

|Step|Belongs to Normalization?|Description|
|---|---|---|
|Lowercasing|✅ Yes|Makes words case-insensitive (`Dog` → `dog`)|
|Removing punctuation|✅ Yes|Removes non-text symbols|
|Removing special characters|✅ Yes|Cleans emojis, symbols|
|Tokenization|❌ Not always|Splits text into words, sentences, etc.|
|Stop words removal|✅ Yes|Removes common function words|
|Stemming|✅ Yes|Reduces words to root form (`studying` → `study`)|
|Lemmatization|✅ Yes|Maps to base dictionary word (`better` → `good`)|
|Spelling correction|✅ Yes|Fixes typos|
|Unicode normalization|✅ Yes|Standardizes characters|
|POS tagging|❌ Not normalization|Adds grammatical meaning|
|Chunking/NER|❌ Not normalization|Extracts structure or named entities|

- **Stemming**
- **Lemmatization**
- **Lowercasing**
- **Stop words removal**

→ all **belong to both** **Text Normalization** and **Text Preprocessing**,  
but **Text Normalization** is specifically about **standardizing word form and structure**.

### 🧠 In Summary

|Concept|Is it Preprocessing?|Is it Normalization?|Why?|
|---|---|---|---|
|Lowercasing|✅|✅|Standardizes case|
|Tokenization|✅|❌|Splits but doesn't simplify|
|Stemming|✅|✅|Simplifies to root form|
|Lemmatization|✅|✅|Normalizes to dictionary base|
|Stop Words Removal|✅|✅|Removes low-information words|
|POS Tagging|✅|❌|Adds grammatical structure|

---
---
