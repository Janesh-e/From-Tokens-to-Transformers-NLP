
# ğŸŒ± STEMMING in NLP :

### What is **Stemming**?

**Stemming** is the process of **reducing a word to its root/base form** (called the _stem_), often by chopping off prefixes or suffixes.

> ğŸ” For example:
> - `connection`, `connected`, `connecting` â†’ `connect`
> - `studies`, `studying` â†’ `studi` (not always grammatically correct)

âš ï¸ **Note:** The result is often **not a valid English word** â€” stemming just reduces words to a rough base form useful for _matching and analysis_, not for grammar.

---

### ğŸ§  Why Do We Need Stemming?

- To **normalize text** for:
    - Text classification
    - Search engines (e.g., searching "running" returns "run", "runs", etc.)
    - Topic modeling and clustering
- To **reduce vocabulary size**, helping simpler ML models generalize better
- To **group semantically similar words** under one form

---

### ğŸ§° Types of Stemmers

##### ğŸ§  1. **Porter Stemmer** â€“ _Rule-Based, Stepwise Algorithm_

> ğŸ“˜ Developed by Martin Porter in 1980. One of the oldest and most widely used stemmers.

#### ğŸ”§ How it works:

- Applies a **series of about 5 steps** with rules to strip suffixes.
- Each step contains rules like:
    - If the word ends with "sses" â†’ replace with "ss"
    - If the word ends with "ing" or "ed", and what's left is a valid stem â†’ remove suffix
- Uses a measure **(m)** â€” a count of vowel-consonant sequences â€” to determine if it's okay to stem.

###### ğŸ§© Example Rules:

- Step 1a:
    - `sses` â†’ `ss`
    - `ies` â†’ `i`
    - `s` â†’ remove only if preceded by a vowel
- Step 1b:
    - Remove `ed`, `ing` if root contains a vowel
- Step 2:
    - `ational` â†’ `ate`
    - `izer` â†’ `ize`

###### âœ… Strengths:

- Reasonably accurate for English
- Reduces vocabulary size well
- Fast

###### âŒ Weaknesses:

- Doesn't care about word meaning â†’ may over-stem
- Outputs aren't always valid words

###### ğŸ“ Example:

```python
# 'relational' -> 'relate'
# Step 2: 'ational' -> 'ate'
```


```python
from nltk.stem import PorterStemmer

porter_stemmer = PorterStemmer()

print(porter_stemmer.stem("running")) Â  Â  # run
print(porter_stemmer.stem("connections")) # connect
print(porter_stemmer.stem("connected")) Â  # connect
print(porter_stemmer.stem("studies")) Â  Â  # studi
print(porter_stemmer.stem("studying")) Â  Â # studi
print(porter_stemmer.stem("maximum")) Â  Â  # maximum
```

---

##### ğŸ§  2. **Lancaster Stemmer** â€“ _Iterative Rule-Based with More Aggression_

> ğŸ“˜ Also known as Paice/Husk stemmer, built by Chris Paice.

###### ğŸ”§ How it works:

- Uses a **lookup table** of rules (e.g., `tional â†’ t`, `ing â†’ null`) and **applies them repeatedly** until no more matches are found.
- Rules are encoded in compact strings: e.g., `tional5t.` means:
    - If word ends in `tional` (length 7), remove 5 chars, append `t`
- Repeats the process until the word canâ€™t be stemmed anymore.

###### âœ… Strengths:

- Very fast
- Works aggressively and compresses vocabulary

###### âŒ Weaknesses:

- Over-stemming (e.g., `university â†’ univ` or even `u`)
- Can remove meaningful parts of the word

###### ğŸ“ Example:

```python
"adjustment" â†’ "adjust" (reasonable)
"maximum" â†’ "maxim" (okay)
"university" â†’ "univers" or even "u" (aggressive!)
```


```python
from nltk.stem import LancasterStemmer

lancaster_stemmer = LancasterStemmer()

print(lancaster_stemmer.stem("running")) Â  Â  Â # run
print(lancaster_stemmer.stem("connections")) Â # connect
print(lancaster_stemmer.stem("connected")) Â  Â # connect
print(lancaster_stemmer.stem("studies")) Â  Â  Â # study
print(lancaster_stemmer.stem("studying")) Â  Â  # study
print(lancaster_stemmer.stem("maximum")) Â  Â  Â # maxim
```

---

##### ğŸ§  3. **Snowball Stemmer** â€“ _An Improved and Modular Porter2 Algorithm_

> ğŸ“˜ Developed by the same person as Porter Stemmer, written in the **Snowball language** (scripting language for writing stemmers).

###### ğŸ”§ How it works:

- Similar in **steps and structure** to Porter but:
    - More consistent and readable
    - More **modular** (can adapt to other languages)
- Uses a more structured rule format: if a suffix matches, it checks character groups and replaces or deletes accordingly.
- Handles **special cases better** and avoids over-stemming.

###### ğŸ“¦ Language support:

- English, French, German, Spanish, Italian, Russian, Dutch, and more.

###### âœ… Strengths:

- Balanced stemming
- Cross-language support
- Output is more linguistically consistent

###### âŒ Weaknesses:

- Still rule-based â†’ no understanding of word context or grammar

```python
from nltk.stem import SnowballStemmer

snowball_stemmer = SnowballStemmer("english")

print(snowball_stemmer.stem("running")) Â  Â  Â  # run
print(snowball_stemmer.stem("connections")) Â  # connect
print(snowball_stemmer.stem("connected")) Â  Â  # connect
print(snowball_stemmer.stem("studies")) Â  Â  Â  # studi
print(snowball_stemmer.stem("studying")) Â  Â  Â # studi
print(snowball_stemmer.stem("maximum")) Â  Â  Â  # maximum
```

---

### âš™ï¸ Internal Mechanics Comparison

|Feature|Porter Stemmer|Lancaster Stemmer|Snowball Stemmer|
|---|---|---|---|
|Type|Rule-based (steps)|Rule-based (iterative)|Rule-based (modular)|
|Aggressiveness|Medium|High|Medium|
|Output validity|Sometimes invalid|Often invalid|Often closer to real|
|Customization|Hard|Moderate|High (for languages)|
|Speed|Fast|Fastest|Fast|

---

### Want to Peek Inside?

You can see the actual rules inside NLTK:

```python
import nltk
nltk.download('all')  # Optional if needed

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
print(ps.stem('relational'))  # Output: relate
```

Or to look at the source rules (for example, for Snowball):

```bash
# If installed via pip, you can browse:
site-packages/nltk/stem/snowball/englishStemmer.py
```

---

### ğŸ§ª Comparison Example

Letâ€™s stem the same word with all three stemmers:

```python
word = "studies"

from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer

porter = PorterStemmer()
lancaster = LancasterStemmer()
snowball = SnowballStemmer("english")

print("Porter:    ", porter.stem(word))    # studi
print("Lancaster: ", lancaster.stem(word)) # study
print("Snowball:  ", snowball.stem(word))  # studi
```

#### ğŸ§¬ Summary â€“ Which One to Use?

- **Use Porter/Snowball** if you want reasonable stemming with fast performance.
- **Use Lancaster** only when:
    - You want very aggressive compression.
    - Youâ€™re okay losing some accuracy.

If you're working with deep NLP or transformer models, use **lemmatization** instead (weâ€™ll go into that next).

---

### ğŸ“Œ When to Use Stemming?

âœ… Use Stemming if:

- You're working on tasks where **perfect grammar isn't necessary** (e.g., search, topic modeling).
- You're using **classic ML models** (like SVM, NB) where vocabulary size affects performance.
- You want **faster preprocessing**.

âŒ Avoid if:

- You're using deep learning or transformer models (they already tokenize effectively).
- You care about semantic correctness or grammar (use **lemmatization** instead â€” weâ€™ll cover that next).

---

### ğŸ“ Summary Table

|Stemming Method|Aggressiveness|Output Examples|Language Support|
|---|---|---|---|
|Porter Stemmer|Medium|`studies â†’ studi`|English only|
|Lancaster Stemmer|High|`studies â†’ study`|English only|
|Snowball Stemmer|Medium-Low|`studies â†’ studi`|Multiple langs|

---
---
