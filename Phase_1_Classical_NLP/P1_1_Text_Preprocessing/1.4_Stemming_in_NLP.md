
# 🌱 STEMMING in NLP :

### What is **Stemming**?

**Stemming** is the process of **reducing a word to its root/base form** (called the _stem_), often by chopping off prefixes or suffixes.

> 🔍 For example:
> - `connection`, `connected`, `connecting` → `connect`
> - `studies`, `studying` → `studi` (not always grammatically correct)

⚠️ **Note:** The result is often **not a valid English word** — stemming just reduces words to a rough base form useful for _matching and analysis_, not for grammar.

---

### 🧠 Why Do We Need Stemming?

- To **normalize text** for:
    - Text classification
    - Search engines (e.g., searching "running" returns "run", "runs", etc.)
    - Topic modeling and clustering
- To **reduce vocabulary size**, helping simpler ML models generalize better
- To **group semantically similar words** under one form

---

### 🧰 Types of Stemmers

##### 🧠 1. **Porter Stemmer** – _Rule-Based, Stepwise Algorithm_

> 📘 Developed by Martin Porter in 1980. One of the oldest and most widely used stemmers.

#### 🔧 How it works:

- Applies a **series of about 5 steps** with rules to strip suffixes.
- Each step contains rules like:
    - If the word ends with "sses" → replace with "ss"
    - If the word ends with "ing" or "ed", and what's left is a valid stem → remove suffix
- Uses a measure **(m)** — a count of vowel-consonant sequences — to determine if it's okay to stem.

###### 🧩 Example Rules:

- Step 1a:
    - `sses` → `ss`
    - `ies` → `i`
    - `s` → remove only if preceded by a vowel
- Step 1b:
    - Remove `ed`, `ing` if root contains a vowel
- Step 2:
    - `ational` → `ate`
    - `izer` → `ize`

###### ✅ Strengths:

- Reasonably accurate for English
- Reduces vocabulary size well
- Fast

###### ❌ Weaknesses:

- Doesn't care about word meaning → may over-stem
- Outputs aren't always valid words

###### 📎 Example:

```python
# 'relational' -> 'relate'
# Step 2: 'ational' -> 'ate'
```


```python
from nltk.stem import PorterStemmer

porter_stemmer = PorterStemmer()

print(porter_stemmer.stem("running"))     # run
print(porter_stemmer.stem("connections")) # connect
print(porter_stemmer.stem("connected"))   # connect
print(porter_stemmer.stem("studies"))     # studi
print(porter_stemmer.stem("studying"))    # studi
print(porter_stemmer.stem("maximum"))     # maximum
```

---

##### 🧠 2. **Lancaster Stemmer** – _Iterative Rule-Based with More Aggression_

> 📘 Also known as Paice/Husk stemmer, built by Chris Paice.

###### 🔧 How it works:

- Uses a **lookup table** of rules (e.g., `tional → t`, `ing → null`) and **applies them repeatedly** until no more matches are found.
- Rules are encoded in compact strings: e.g., `tional5t.` means:
    - If word ends in `tional` (length 7), remove 5 chars, append `t`
- Repeats the process until the word can’t be stemmed anymore.

###### ✅ Strengths:

- Very fast
- Works aggressively and compresses vocabulary

###### ❌ Weaknesses:

- Over-stemming (e.g., `university → univ` or even `u`)
- Can remove meaningful parts of the word

###### 📎 Example:

```python
"adjustment" → "adjust" (reasonable)
"maximum" → "maxim" (okay)
"university" → "univers" or even "u" (aggressive!)
```


```python
from nltk.stem import LancasterStemmer

lancaster_stemmer = LancasterStemmer()

print(lancaster_stemmer.stem("running"))      # run
print(lancaster_stemmer.stem("connections"))  # connect
print(lancaster_stemmer.stem("connected"))    # connect
print(lancaster_stemmer.stem("studies"))      # study
print(lancaster_stemmer.stem("studying"))     # study
print(lancaster_stemmer.stem("maximum"))      # maxim
```

---

##### 🧠 3. **Snowball Stemmer** – _An Improved and Modular Porter2 Algorithm_

> 📘 Developed by the same person as Porter Stemmer, written in the **Snowball language** (scripting language for writing stemmers).

###### 🔧 How it works:

- Similar in **steps and structure** to Porter but:
    - More consistent and readable
    - More **modular** (can adapt to other languages)
- Uses a more structured rule format: if a suffix matches, it checks character groups and replaces or deletes accordingly.
- Handles **special cases better** and avoids over-stemming.

###### 📦 Language support:

- English, French, German, Spanish, Italian, Russian, Dutch, and more.

###### ✅ Strengths:

- Balanced stemming
- Cross-language support
- Output is more linguistically consistent

###### ❌ Weaknesses:

- Still rule-based → no understanding of word context or grammar

```python
from nltk.stem import SnowballStemmer

snowball_stemmer = SnowballStemmer("english")

print(snowball_stemmer.stem("running"))       # run
print(snowball_stemmer.stem("connections"))   # connect
print(snowball_stemmer.stem("connected"))     # connect
print(snowball_stemmer.stem("studies"))       # studi
print(snowball_stemmer.stem("studying"))      # studi
print(snowball_stemmer.stem("maximum"))       # maximum
```

---

### ⚙️ Internal Mechanics Comparison

|Feature|Porter Stemmer|Lancaster Stemmer|Snowball Stemmer|
|---|---|---|---|
|Type|Rule-based (steps)|Rule-based (iterative)|Rule-based (modular)|
|Aggressiveness|Medium|High|Medium|
|Output validity|Sometimes invalid|Often invalid|Often closer to real|
|Customization|Hard|Moderate|High (for languages)|
|Speed|Fast|Fastest|Fast|

---

### Want to Peek Inside?

You can see the actual rules inside NLTK:

```python
import nltk
nltk.download('all')  # Optional if needed

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
print(ps.stem('relational'))  # Output: relate
```

Or to look at the source rules (for example, for Snowball):

```bash
# If installed via pip, you can browse:
site-packages/nltk/stem/snowball/englishStemmer.py
```

---

### 🧪 Comparison Example

Let’s stem the same word with all three stemmers:

```python
word = "studies"

from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer

porter = PorterStemmer()
lancaster = LancasterStemmer()
snowball = SnowballStemmer("english")

print("Porter:    ", porter.stem(word))    # studi
print("Lancaster: ", lancaster.stem(word)) # study
print("Snowball:  ", snowball.stem(word))  # studi
```

#### 🧬 Summary – Which One to Use?

- **Use Porter/Snowball** if you want reasonable stemming with fast performance.
- **Use Lancaster** only when:
    - You want very aggressive compression.
    - You’re okay losing some accuracy.

If you're working with deep NLP or transformer models, use **lemmatization** instead (we’ll go into that next).

---

### 📌 When to Use Stemming?

✅ Use Stemming if:

- You're working on tasks where **perfect grammar isn't necessary** (e.g., search, topic modeling).
- You're using **classic ML models** (like SVM, NB) where vocabulary size affects performance.
- You want **faster preprocessing**.

❌ Avoid if:

- You're using deep learning or transformer models (they already tokenize effectively).
- You care about semantic correctness or grammar (use **lemmatization** instead — we’ll cover that next).

---

### 📎 Summary Table

|Stemming Method|Aggressiveness|Output Examples|Language Support|
|---|---|---|---|
|Porter Stemmer|Medium|`studies → studi`|English only|
|Lancaster Stemmer|High|`studies → study`|English only|
|Snowball Stemmer|Medium-Low|`studies → studi`|Multiple langs|

---
---
